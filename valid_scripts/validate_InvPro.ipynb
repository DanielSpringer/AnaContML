{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4ce8a6-77f1-499b-b3b0-aeee72468803",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKDIR = \"/mnt/scratch/daniel/Data/AnaContML\"\n",
    "\n",
    "import sys\n",
    "sys.path.append(WORKDIR+\"/src\")\n",
    "import os\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\"\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import load_data\n",
    "import datetime\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from pytorch_lightning.plugins.environments import LightningEnvironment\n",
    "import json\n",
    "import numpy as np\n",
    "import h5py\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "# from pympler import asizeof\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac43b396-0cbb-42d7-a3d2-293e7b10f229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(config):\n",
    "    data = np.load(config[\"PATH_TRAIN\"])\n",
    "    train, validation = torch.utils.data.random_split(data, [int(data.__len__()*config[\"SPLIT\"]), int(data.__len__())-int(data.__len__()*config[\"SPLIT\"])], generator=torch.Generator().manual_seed(42))\n",
    "    return train, validation\n",
    "\n",
    "\n",
    "data_dict = {}\n",
    "def validate():\n",
    "    ## JSON File contains full information about entire run (model, data, hyperparameters)\n",
    "    MODEL_NAME = \"GNN_1_base\"\n",
    "    config = json.load(open(WORKDIR+'/_runs/confmod_graph_neural_network_MIT_w100_n100_skew1.json'))[MODEL_NAME]\n",
    "    print(config)\n",
    "    config[\"batch_size\"] = 1\n",
    "\n",
    "    # ''' Dataloading '''\n",
    "    train_data, validation_data = create_datasets(config)\n",
    "    train_data = np.array(train_data)\n",
    "    validation_data = np.array(validation_data)\n",
    "\n",
    "    # ### > Single HDF5 file containing training and validation data \n",
    "    ld = __import__(\"load_data\", fromlist=['object'])\n",
    "    train_set = getattr(ld, config[\"DATA_LOADER\"])(config, train_data)\n",
    "    validation_set = getattr(ld, config[\"DATA_LOADER\"])(config, validation_data)\n",
    "    train_dataloader = DataLoader(train_set, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "    validation_dataloader = DataLoader(validation_set, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "\n",
    "    ''' Storage '''\n",
    "    t_samples = np.asarray(train_set).shape[0]\n",
    "    v_samples = np.asarray(validation_set).shape[0]\n",
    "\n",
    "    data_dict[\"train\"] = {}\n",
    "    data_dict[\"train\"][\"green\"] = torch.zeros((t_samples, config[\"tau_steps\"]))\n",
    "    data_dict[\"train\"][\"prediction\"] = torch.zeros((t_samples, config[\"omega_steps\"]))\n",
    "    data_dict[\"train\"][\"target\"] = torch.zeros((t_samples, config[\"omega_steps\"]))\n",
    "    data_dict[\"train\"][\"p_coefficients\"] = torch.zeros((t_samples, config[\"n_nodes\"]))\n",
    "    data_dict[\"train\"][\"vectors\"] = torch.zeros((t_samples, config[\"n_nodes\"], config[\"omega_steps\"]))\n",
    "\n",
    "    data_dict[\"valid\"] = {}\n",
    "    data_dict[\"valid\"][\"green\"] = torch.zeros((v_samples, config[\"tau_steps\"]))\n",
    "    data_dict[\"valid\"][\"prediction\"] = torch.zeros((v_samples, config[\"omega_steps\"]))\n",
    "    data_dict[\"valid\"][\"target\"] = torch.zeros((v_samples, config[\"omega_steps\"]))\n",
    "    data_dict[\"valid\"][\"p_coefficients\"] = torch.zeros((v_samples, config[\"n_nodes\"]))\n",
    "    data_dict[\"valid\"][\"vectors\"] = torch.zeros((v_samples, config[\"n_nodes\"], config[\"omega_steps\"]))\n",
    "\n",
    "    beta = [10, 20, 30, 40]\n",
    "    data_dict[\"ctqmc\"] = {}\n",
    "    for b in beta:\n",
    "        data_dict[\"ctqmc\"][b] = {}\n",
    "        data_dict[\"ctqmc\"][b][\"green\"] = torch.zeros((40, config[\"tau_steps\"]))\n",
    "        data_dict[\"ctqmc\"][b][\"prediction\"] = torch.zeros((40, config[\"omega_steps\"]))\n",
    "        data_dict[\"ctqmc\"][b][\"p_coefficients\"] = torch.zeros((40, config[\"n_nodes\"]))\n",
    "        data_dict[\"ctqmc\"][b][\"vectors\"] = torch.zeros((40, config[\"n_nodes\"], config[\"omega_steps\"]))\n",
    "        data_dict[\"ctqmc\"][b][\"U\"] = torch.zeros(40)\n",
    "\n",
    "    \n",
    "    ''' Model setup '''\n",
    "    wrapers = __import__(\"wrappers.wrapers\", fromlist=['object'])#.wrapers\n",
    "    model = getattr(wrapers, config[\"MODEL_WRAPER\"])(config)\n",
    "\n",
    "    ''' Model loading from save file '''\n",
    "    if config[\"continue\"] == True:\n",
    "        SAVEPATH = config[\"SAVEPATH\"]\n",
    "        if torch.cuda.is_available():\n",
    "            checkpoint = torch.load(SAVEPATH)\n",
    "        else:\n",
    "            checkpoint = torch.load(SAVEPATH, map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        print(\" >>> Loaded checkpoint\")\n",
    "    \n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model = model.to(device)\n",
    "        # model.eval()\n",
    "    \n",
    "\n",
    "    start = time.time()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for b in beta:\n",
    "            PATH = WORKDIR+f\"/valid_scripts/gtau_beta{str(b)}_w2dyn/beta{b}/\"\n",
    "            gtau_ctqmc = []\n",
    "            nono = []\n",
    "            _ = np.load(PATH+\"data.npz\", allow_pickle=True)\n",
    "            data = {key: _[key].item() for key in _}\n",
    "            for U in data.keys():\n",
    "                gtau_ctqmc.append(data[U][\"gtau\"][0,0,:])\n",
    "                nono.append([np.zeros_like(gtau_ctqmc) + int(U)][0][0])\n",
    "            gtau_ctqmc = np.array(gtau_ctqmc)\n",
    "            nono = np.array(nono)            \n",
    "    \n",
    "            step = 10\n",
    "            gtau_ctqmc = np.concatenate((\n",
    "                gtau_ctqmc[:, 0][:, None],                     # first point\n",
    "                gtau_ctqmc[:, step:-step:step],               # 98 intermediate points\n",
    "                gtau_ctqmc[:, -1][:, None]                    # last point\n",
    "            ), axis=1)\n",
    "            nono = np.concatenate((\n",
    "                nono[:, 0][:, None],                     # first point\n",
    "                nono[:, step:-step:step],               # 98 intermediate points\n",
    "                nono[:, -1][:, None]                    # last point\n",
    "            ), axis=1)\n",
    "            data_ctqmc = np.concatenate((gtau_ctqmc[:,None,:], nono[:,None,:]), axis=1)\n",
    "            \n",
    "            ctqmc_set = getattr(ld, config[\"DATA_LOADER\"])(config, data_ctqmc)\n",
    "            ctqmc_dataloader = DataLoader(ctqmc_set, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "    \n",
    "            for n, batch in enumerate(ctqmc_dataloader):\n",
    "                # Move batch data to GPU\n",
    "                batch_gpu = {}\n",
    "                for k, v in batch.items():\n",
    "                    if torch.is_tensor(v):\n",
    "                        batch_gpu[k] = v.to(device, non_blocking=True)\n",
    "                    else:\n",
    "                        batch_gpu[k] = v\n",
    "    \n",
    "                out = model.model.forward(batch_gpu)\n",
    "                data_dict[\"ctqmc\"][b][\"green\"][n] = batch_gpu[\"node_feature\"][0,0,config[\"omega_steps\"]:]\n",
    "                data_dict[\"ctqmc\"][b][\"prediction\"][n] = out[0][0]\n",
    "                data_dict[\"ctqmc\"][b][\"vectors\"][n] = out[1][0]\n",
    "                data_dict[\"ctqmc\"][b][\"p_coefficients\"][n] = out[2][0,:,0]\n",
    "                data_dict[\"ctqmc\"][b][\"U\"][n] = batch_gpu[\"target\"][0][0]\n",
    "        print(\"  CTQMC DONE   \")\n",
    "            \n",
    "        ## TRAINING DATA\n",
    "        for n, batch in enumerate(train_dataloader):\n",
    "            # Move batch data to GPU\n",
    "            batch_gpu = {}\n",
    "            for k, v in batch.items():\n",
    "                if torch.is_tensor(v):\n",
    "                    batch_gpu[k] = v.to(device, non_blocking=True)\n",
    "                else:\n",
    "                    batch_gpu[k] = v\n",
    "\n",
    "            out = model.model.forward(batch_gpu)            \n",
    "            data_dict[\"train\"][\"green\"][n] = batch_gpu[\"node_feature\"][0,0,config[\"omega_steps\"]:]\n",
    "            data_dict[\"train\"][\"target\"][n] = batch_gpu[\"target\"]\n",
    "            # data_dict[\"train\"][\"prediction\"][n] = model.model.forward(batch_gpu)\n",
    "            data_dict[\"train\"][\"prediction\"][n] = out[0][0]\n",
    "            data_dict[\"train\"][\"vectors\"][n] = out[1][0]\n",
    "            data_dict[\"train\"][\"p_coefficients\"][n] = out[2][0,:,0]\n",
    "            \n",
    "            \n",
    "            call_time = 1e4\n",
    "            if n % call_time == 0:\n",
    "                end = time.time()\n",
    "                print(f\"{n} / {len(train_dataloader)}    Step time: {end - start:.4f} sec\")\n",
    "                remaining = (len(train_dataloader) - n) * (end - start) / 60 / call_time\n",
    "                print(f\"Estimated time left: {remaining:.2f} minutes\")\n",
    "                start = time.time()\n",
    "\n",
    "        ### VALIDATION DATA\n",
    "        for n, batch in enumerate(validation_dataloader):\n",
    "            # Move batch data to GPU\n",
    "            batch_gpu = {}\n",
    "            for k, v in batch.items():\n",
    "                if torch.is_tensor(v):\n",
    "                    batch_gpu[k] = v.to(device, non_blocking=True)\n",
    "                else:\n",
    "                    batch_gpu[k] = v\n",
    "\n",
    "            out = model.model.forward(batch_gpu)\n",
    "            data_dict[\"valid\"][\"green\"][n] = batch_gpu[\"node_feature\"][0,0,config[\"omega_steps\"]:]\n",
    "            data_dict[\"valid\"][\"target\"][n] = batch_gpu[\"target\"]\n",
    "            # data_dict[\"valid\"][\"prediction\"][n] = model.model.forward(batch_gpu)\n",
    "            data_dict[\"valid\"][\"prediction\"][n] = out[0][0]\n",
    "            data_dict[\"valid\"][\"vectors\"][n] = out[1][0]\n",
    "            data_dict[\"valid\"][\"p_coefficients\"][n] = out[2][0,:,0]\n",
    "            \n",
    "            call_time = 5e3\n",
    "            if n % call_time == 0:\n",
    "                end = time.time()\n",
    "                print(f\"{n} / {len(validation_dataloader)}    Step time: {end - start:.4f} sec\")\n",
    "                remaining = (len(validation_dataloader) - n) * (end - start) / 60 / call_time\n",
    "                print(f\"Estimated time left: {remaining:.2f} minutes\")\n",
    "                start = time.time()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    validate()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14d5858-6900-430b-9296-c92e75310ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dict_to_hdf5_group(h5file, path, dictionary):\n",
    "    \"\"\"\n",
    "    Recursively save a nested dictionary to HDF5 groups\n",
    "    \"\"\"\n",
    "    for key, item in dictionary.items():\n",
    "        key_str = str(key)\n",
    "        if isinstance(item, dict):\n",
    "            grp = h5file.create_group(f\"{path}/{key_str}\")\n",
    "            save_dict_to_hdf5_group(h5file, f\"{path}/{key_str}\", item)\n",
    "        else:\n",
    "            # assume item is array-like or scalar\n",
    "            h5file.create_dataset(f\"{path}/{key_str}\", data=np.array(item))\n",
    "            \n",
    "with h5py.File(\"GNN_1_base_MIT_skew_2025-11-28_100_bs100_v2.h5\", \"w\") as f:\n",
    "    save_dict_to_hdf5_group(f, \"train\", data_dict[\"train\"])\n",
    "    save_dict_to_hdf5_group(f, \"valid\", data_dict[\"valid\"])\n",
    "    save_dict_to_hdf5_group(f, \"ctqmc\", data_dict[\"ctqmc\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
